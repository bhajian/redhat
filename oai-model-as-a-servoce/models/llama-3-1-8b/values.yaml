namespace: llama31-8b
model:
  name: llama-3-1-8b-instruct-fp8-dynamic
  displayName: "Llama 3.1 8B Instruct (FP8)"
  runtimeName: vllm-cuda-runtime
  storageUri: oci://registry.redhat.io/rhelai1/modelcar-llama-3-1-8b-instruct-fp8-dynamic:1.5
  minReplicas: 1
  maxReplicas: 1
  resources:
    requests: { cpu: "1", memory: 4Gi, gpu: "1" }
    limits:   { cpu: "2", memory: 8Gi, gpu: "1" }
  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule

litellm:
  replicas: 1
  masterKey: "demo-change-me"   # for demo; replace via Secret in real use
