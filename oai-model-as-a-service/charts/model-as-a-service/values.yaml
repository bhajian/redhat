namespace: llm-demo

model:
  name: llama-3-1-8b-instruct-fp8-dynamic
  displayName: "Llama 3.1 8B Instruct (FP8)"
  runtimeName: vllm-cuda-runtime
  storageUri: oci://registry.redhat.io/rhelai1/modelcar-llama-3-1-8b-instruct-fp8-dynamic:1.5
  minReplicas: 1
  maxReplicas: 1
  resources:
    requests:
      cpu: "1"
      memory: 4Gi
      gpu: "1"
    limits:
      cpu: "2"
      memory: 8Gi
      gpu: "1"
  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule

litellm:
  replicas: 1
  masterKey: "demo-change-me"     # demo only; for real use put a Secret via ArgoCD plugin
  image: ghcr.io/berriai/litellm:latest
