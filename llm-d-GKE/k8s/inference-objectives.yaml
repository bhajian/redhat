apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: llama3-8b # Matches your --served-model-name
spec:
  priority: 20
  poolRef:
    # This MUST match your Helm release name
    name: vllm-llama3-8b-instruct
    group: "inference.networking.k8s.io"
---
apiVersion: inference.networking.x-k8s.io/v1alpha2
kind: InferenceObjective
metadata:
  name: food-review-1 # Matches the LoRA adapter from your ConfigMap
spec:
  priority: 10
  poolRef:
    # This MUST match your Helm release name
    name: vllm-llama3-8b-instruct
    group: "inference.networking.k8s.io"